---
title: "Lab3"
author: "Pablo Gonzalez, Jose Hernandez, Javier Mombiela"
date: "2023-03-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, echo=FALSE}
library(dplyr)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
library(dplyr)
library(nortest)

```


# Laboratorio 3

## Carga de datos
```{r}
datos <- read.csv("train.csv")

```

## Variables numericas
```{r}
num_vars_numericas <- sapply(datos,is.numeric)
print(num_vars_numericas)


```


## Resumen datos para verificar si son numericos
```{r datos}
summary(datos)
```
Id: Cuantitativa	
MSSubClass: Cuantitativa	
MSZoning: Cualitativa	
LotFrontage: Cuantitativa
LotArea: Cuantitativa
Street: Cualitativa	
Alley: Cualitativa
LotShape: Cualitativa	
LandContour: Cualitativa
Utilities: Cualitativa
LotConfig	: Cualitativa
LandSlope: Cualitativa
Neighborhood: Cualitativa	
Condition1: Cualitativa	
Condition2: Cualitativa
BldgType: Cualitativa	
HouseStyle: Cualitativa	
OverallQual: Cuantitativa	
OverallCond: Cuantitativa	
YearBuilt: Cuantitativa	
YearRemodAdd: Cuantitativa	
RoofStyle: Cualitativa	
RoofMatl: Cualitativa	
Exterior1st: Cualitativa
Exterior2nd: Cualitativa
MasVnrType: Cualitativa	
MasVnrArea: Cuantitativa	
ExterQual: Cualitativa	
ExterCond: Cualitativa	
Foundation: Cualitativa	
BsmtQual: Cualitativa	
BsmtCond: Cualitativa	
BsmtExposure: Cualitativa	
BsmtFinType1: Cualitativa	
BsmtFinSF1: Cuantitativa	
BsmtFinType2: Cualitativa	
BsmtFinSF2: Cuantitativa	
BsmtUnfSF: Cuantitativa	
TotalBsmtSF: Cuantitativa	
Heating: Cualitativa	
HeatingQC: Cualitativa	
CentralAir: Cualitativa	
Electrical: Cualitativa	
1stFlrSF: Cuantitativa	
2ndFlrSF: Cuantitativa	
LowQualFinSF: Cuantitativa	
GrLivArea: Cuantitativa	
BsmtFullBath: Cuantitativa	
BsmtHalfBath: Cuantitativa	
FullBath: Cuantitativa	
HalfBath: Cuantitativa	
BedroomAbvGr: Cuantitativa	
KitchenAbvGr: Cuantitaiva
KitchenQual: Cualitativa	
TotRmsAbvGrd: Cuantitativa
Functional: Cualitativa	
Fireplaces: Cuantitativa	
FireplaceQu: Cualitativa	
GarageType: Cualitativa	
GarageYrBlt: Cuantintativa	
GarageFinish: Cualitativa	
GarageCars: Cuantitativa	
GarageArea: Cuantitativa	
GarageQual: Cualitativa	
GarageCond: Cualitativa	
PavedDrive: Cualitativa	
WoodDeckSF: Cuantitativa	
OpenPorchSF: Cuantitativa	
EnclosedPorch: Cuantitativa	
3SsnPorch: Cuantitativa	
ScreenPorch: Cuantiativa	
PoolArea: Cuantitativa	
PoolQC: Cualitativa	
Fence: Cualitativa	
MiscFeature: Cuantitativa	
MiscVal	MoSold: Cuantitativa	
YrSold: Cuantitativa	
SaleType: Cualitativa	
SaleCondition: Cuantitativa	
SalePrice: Cuantitativa







## Data frame con los datos numericos
```{r}
datos_numericos <-select_if(datos,is.numeric)
datos_numericos <-datos_numericos[complete.cases(datos_numericos),]

```
## Data frame normalizado
```{r}
datos_numericos <-scale(na.omit(datos_numericos))
```


# Analizar si se puede hacer agrupamiento por medio de hopkings
```{r}
set.seed(123)
hopkins(datos_numericos)
datos_dist <- dist(datos_numericos)

```
Como se puede visualizar al momento de hacer el hopkings del set de datos el valor resultante fue de 1 por lo que se puede mencionar que este esta alejado del 0.5 por lo que se puede proceder a hacer el metodo de agrupamiento

```{r}
wss=0
for (i in 1:10) 
  wss[i] <- sum(kmeans(datos_numericos, centers=i)$withinss)
plot(1:10, wss, type="b", xlab="Number of Clusters",  ylab="Within groups sum of squares")
```

```{r}
fviz_nbclust(datos_numericos[,1:4], kmeans, method = "silhouette") +
labs(subtitle = "Silhouette method")

```
Se puede visualizar que el numero de Klusters para este set de datos es de 2


## Analisis jerarquico
```{r}
matriz_dist<- dist(datos_numericos)
```




```{r}
hc <-hclust(datos_dist,method = "ward.D2")
plot(hc, cex=0.5)
rect.hclust(hc,k=2)

```
```{r}
fviz_dend(hc, k=2, rect = T, cex = .5)
```


## Calcular la correlacion de todas las variables con la variable de precio de casas
```{r}

cor(datos_numericos)
```
Como se puede visualizar en la tabla para el dato de Saleprice existen dos columnas con una relacion mayor a 0.7 las cuales son GrLivArea y OverallQual por lo que procedera a crear un data set con estas variables aisladas

## Regresion lineal simple

```{r}
id <- as.numeric(datos_numericos[,"Id"])
GrLivArea <- as.numeric(datos_numericos[,"GrLivArea"])
OverallQual <- as.numeric(datos_numericos[,"OverallQual"])
SalePrice <- as.numeric(datos_numericos[,"SalePrice"])
datos_regresion <- data.frame(id,GrLivArea,OverallQual,SalePrice)

  
porcentaje <-0.7
corte <-sample(nrow(datos_regresion),nrow(datos_regresion)*porcentaje)
train <-data.frame(datos_numericos[corte,])
test <- data.frame(datos_numericos[-corte,])

```

Conjunto de entramiento
```{r}
head(train)
```
Conjunto de test
```{r}
head(test)
```

```{r}
fitLPMW <-lm(SalePrice~OverallQual,data = train)
fitLPMW

```
La ecuacion de la regresion se puede escribir de la siguiente manera
$SalePrice = `r round(fitLPMW$coefficients[2],2)` OverallQual + `r round(fitLPMW$coefficients[1],2)`$ 

Representacion del modelo
```{r}
library(ggplot2)
ggplot(data = train, mapping = aes(x = OverallQual, y = SalePrice)) +
geom_point(color = "firebrick", size = 2) +
geom_smooth(method = "lm", se = TRUE, color = "black") +
labs(title = "OverallQual ~ SalePrice", x = "Overallqual", y = "SalesPrice") +
theme_bw() + theme(plot.title = element_text(hjust = 0.5))
```

### Resumen del modelo
Analicis del resumen del modelo
```{r}
summary(fitLPMW)
```
Se puede mencionar que el primer modelo tien un r^2 de 0.63

#Eror cuadratico medio para el primer modelo
```{r}
mse <-mean(resid(fitLPMW)^2)
mse
```
Se puede mencionar que el error cuadratico medio para el primero modelo es de 
0.3122
#Error absoluto medio
```{r}
mae <-mean(abs(resid(fitLPMW)))
mae
```
Se puede menncionar que el eror absoluto medio de para el primer modelo es de 
0.39


### Analisis de residuales 
```{r}
predL<-predict(fitLPMW, newdata = test)
```

La prediccion se ve de esta manera
```{r}
head(predL)
```

```{r}
length(predL)
```

```{r}
head(fitLPMW$residuals)
```




```{r}
plot(fitLPMW)
```

```{r}
hist(fitLPMW$residuals)
```

```{r}
qqnorm(fitLPMW$residuals)
qqline(fitLPMW$residuals, col="red")
```

```{r}
library(nortest)
lillie.test(fitLPMW$residuals)
```




### Hallando el SalePrice para un cojunto de prueba
```{r}
predLM<-predict(fitLPMW, newdata = test[,c(1,2,4)])
```

```{r}
plot(test$SalePrice,col="blue")
points(predLM, col="red")
```





## Segundo modelo

## Regresion lineal multiple
```{r}
datos_df <- as.data.frame(datos_numericos)
multiples <-lm(SalePrice~.,data = datos_df)
```

### Resumen del modelo
```{r}
summary(multiples)
```
Se puede mencionar que el r^2 para el segudo modelo es de 0.81

#Error medio cuadrtico del modelo mutiples
```{r}
mse2 <-mean(resid(multiples)^2)
mse2

```
Se puede mencionar que el error medio cuadratico del modelo de multiples es de 0.19
#Error absoluto medio del modelo de multiples
```{r}
mae2 <-mean(abs(resid(multiples)))
mae2
```
Se puede mencionar que el error absoluto medio del modelo de multiples es de
0.27

### Analisis de residuales segundo modelo
```{r}
predL2<-predict(multiples, newdata = test)
```
La prediccion se ve de esta manera
```{r}
head(predL2)
```

```{r}
length(predL2)
```

```{r}
head(multiples$residuals)
```


```{r}
plot(multiples)
```

```{r}
hist(multiples$residuals)
```

```{r}
qqnorm(multiples$residuals)
qqline(multiples$residuals, col="red")
```

```{r}
library(nortest)
lillie.test(multiples$residuals)
```




### Hallando el SalePrice para un cojunto de prueba


```{r}
predMlm2 <-predict(multiples,newdata = test[])
```
```{r}
plot(test$SalePrice,col="blue")
points(predMlm2, col="red")
```

###Seleccion de modelo
En general, se puede mencionar que un r^2 mas alto indica que el modelo tiene un mejor ajuste a los daros, como sepuede visualizar el primer modelo tiene un r^2 de 0.63, lo que sigfica que el 63% de la variabilidad en los datos se explica por el modelo, mientras que el segundo modelo el cual toma en cuenta mas variables tiene un r^2 de 0.81%, lo que significa de la variabilidad en los datos se explica por el modelo, por lo tanto el segundo modelo tiene un mejor r^2. Ademas se peude mencionar que el error medio cuadrado rmse es otra medida de precision del modelo por lo que el rmse mas bajo indica una mejor precision en el modelo por lo que el segundo modelo vuelvo a tener una medida mas baja la cual es de 0.19 en comparacion con el primero de 0.31, Por lo que se puede concluir que el segundo modelo de multicoleanidad tambien se puede visualizar en la grafica del modelo que este tiene un mejor desempeño con la prueba de datos por lo que se seleccionaia este modelo como el mejor modelo para los datos descritos.







